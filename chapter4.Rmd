---
title: "Exercise 4"
author: "Tiina Siponen"
date: "15.11.2019"
output: html_document
---

# Exercise 4
*Work summary*

Codes are available at 

- <https://github.com/tiinasip/IODS-project/blob/master/Boston.R>
- <https://github.com/tiinasip/IODS-project/blob/master/Boston2.R>
- <https://github.com/tiinasip/IODS-project/blob/master/Boston3.R>
- <https://github.com/tiinasip/IODS-project/blob/master/create_human.R>


## Data load and description
Boston dataset contains information collected by the U.S Census Service concerning housing valuesin the area of Boston Mass. It was obtained from the StatLib archive. More information about each variable can be found in [here](https://stat.ethz.ch/R-manual/R-devel/library/MASS/html/Boston.html) 

Descriptions of variables are:
- CRIM: Per capita crime rate by town
- ZN Proportion of residential land zoned for lots over 25,000 sq. ft
- INDUS: Proportion of non-retail business acres per town
- CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)
- NOX: Nitric oxide concentration (parts per 10 million)
- RM: Average number of rooms per dwelling
- AGE: Proportion of owner-occupied units built prior to 1940
- DIS: Weighted distances to five Boston employment centers
- RAD: Index of accessibility to radial highways
- TAX: Full-value property tax rate per $10,000
- PTRATIO: Pupil-teacher ratio by town
- B: 1000(Bk — 0.63)², where Bk is the proportion of [people of African American descent] by town
- LSTAT: Percentage of lower status of the population
- MEDV: Median value of owner-occupied homes in $1000s


```{r readdata 20,echo=TRUE,message=FALSE,warning=FALSE}
library(MASS)
data("Boston")
dim(Boston)
str(Boston)
summary(Boston)
```

According to the information the Boston data frame has 506 rows and 14 columns. That is equal to my check. There is no missing values either. 
```{r readdata 29,echo=TRUE,message=FALSE,warning=FALSE}
sum(is.na(Boston))
mean(is.na(Boston))
```

From graphical overview it is easy to notice at least the following:
- rm & medv, nox & indus, age & nox, tax & indus have positive correlation
- dis & indus, dis & nox, dis & age, lstat & medv have negative correation
- medv and rm seem to fit linear distribution 
- age and black are left-tailed
- crim, dis are right-tailed
- tax, rad and indus are bimodally distributed
- lstat, nox and dis are skewed to the left

```{r readdata 19,echo=TRUE,message=FALSE,warning=FALSE}
library(GGally)
library(ggplot2)
 ggpairs(Boston, mapping = aes(), title="Scatter plot matrix, distributions ",lower = list(combo = wrap("facethist", bins = 20)))
```

![Alt text](C:/Users/SIPONENTI/Documents/IODS-project/figures/Ex4_distributions.png)


```{r fig21, fig.path="figures/",fig.dim=c(12,12)}
pairs(Boston[-1], main="Graphical summary")
```

## Standardization
Scaling targets to normalising:
```{r readdata 21,echo=TRUE,message=FALSE,warning=FALSE}
boston_scaled <- scale(Boston)
summary(boston_scaled)

```

When summary of scaled data is compared to the original data, it is easy to see that magnitudes of min and max values have decreased and mean is always 0. For instance, max of lstat was 37.97 and after scaling 3.54, respectively black max 396.9 and 0.44. Zn min was 0, now -0.49, rm min was 3.56, now -3.88.

Categorial variable crim is created:
```{r readdata 22,echo=TRUE,message=FALSE,warning=FALSE}
# change the object to data frame, because vector otherwise causes an error in next phase
boston_scaled<-as.data.frame(boston_scaled)
bins <- quantile(boston_scaled$crim)
bins
crime <- cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, labels = c("low", "med_low", "med_high", "high"))
table(crime)
# remove original crim from the dataset
boston_scaled <- dplyr::select(boston_scaled, -crim)
# add the new categorical value to scaled data
boston_scaled <- data.frame(boston_scaled, crime)

```

Testing and training sets are created:
```{r readdata 23,echo=TRUE,message=FALSE,warning=FALSE}
# number of rows in the Boston dataset 
n <- nrow(boston_scaled)
# randomly 80% of the rows
ind <- sample(n,  size = n * 0.8)
# creating train set
train <- boston_scaled[ind,]
# create testing set 
test <- boston_scaled[-ind,]
# save the correct classes from test data
correct_classes <- test$crime
# remove the crime variable from test data
test <- dplyr::select(test, -crime)
```



## LDA

```{r readdata 30,echo=TRUE,message=FALSE,warning=FALSE}
lda.fit <- lda(crime~., data = train)
lda.fit
# the function for lda biplot arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
  heads <- coef(x)
  arrows(x0 = 0, y0 = 0, 
         x1 = myscale * heads[,choices[1]], 
         y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
  text(myscale * heads[,choices], labels = row.names(heads), 
       cex = tex, col=color, pos=3)
}
# target classes as numeric
classes <- as.numeric(train$crime)

```


```{r fig28, fig.path="figures/"}
# plot the lda results
plot(lda.fit, dimen = 2, col=classes, pch=classes)
lda.arrows(lda.fit, myscale = 1)
lda.pred <- predict(lda.fit, newdata = test)
```

```{r readdata 31,echo=TRUE,message=FALSE,warning=FALSE}
# cross tabulate the results
table(correct = correct_classes, predicted = lda.pred$class)
```
	6. Save the crime categories from the test set and then remove the categorical crime variable from the test dataset. Then predict the classes with the LDA model on the test data. Cross tabulate the results with the crime categories from the test set. Comment on the results. (0-3 points)

## Distances and kmeans

Boston dataset is reloaded again and the done modifications are not valid any more. Data is standardi
```{r readdata 24,echo=TRUE,message=FALSE,warning=FALSE}
library(MASS)
data("Boston")
summary(Boston)
boston_scaled2 <- scale(Boston)
summary(boston_scaled2)
class(boston_scaled2)
boston_scaled2<-as.data.frame(boston_scaled2)
```

Distances calculation:
```{r readdata 25,echo=TRUE,message=FALSE,warning=FALSE}
dist_eu<- dist(boston_scaled2)
summary(dist_eu)
```

Kmeans clustering and pairs are calculated, but the number of centers here is 4, which is just a guess what could be the optimal number.
```{r fig22, fig.path="figures/",fig.dim=c(12,12)}
km <-kmeans(boston_scaled2, centers = 4)
pairs(boston_scaled2, col = km$cluster)
```
To find the optimal number of clusters is not irrelevant question and the textbook recommends the method to plot within-group sum of squares associated with the k-means solution for each number of groups. Then the "elbow" in the picture gives indication of the most useful solution. The plot below indicates that the elbow is in 2, after 2 the decrease is slower. However, even with 3 it is still significant but I choose to use 2.

```{r fig23, fig.path="figures/",fig.dim=c(12,12)}
set.seed(123)
# determine the number of clusters
k_max <- 10
# calculate the total within sum of squares
twcss <- sapply(1:k_max, function(k){kmeans(boston_scaled2, k)$tot.withinss})
# visualize the results
qplot(x = 1:k_max, y = twcss, geom = 'line', main="WGSS and groups in K-means solution")
```
Only 51 % total variance in  data set that is explained by the first clustering with 4 clusters, which is not impressive. I checked how many clusters I should have to gain 80 % of total variance and it was 20. It is clear that it is too much, so I still keep 2 clusters, although the biggest decrease of variation ends at 2. In real-life I should check the correct number of clusters also by other methods, e.g. silhouette.


```{r readdata 26,echo=TRUE,message=FALSE,warning=FALSE}
str(km)
km
```
The plot picture shows the groups are not equal size, one is 177 and other 329. There are some pairs, in which the grouping seems to work nicely; for instance medvd & lstat, lstat & nox,dis & nox and rm & nox. But for some pairs the groups are unclear, for instance rm&ptratio, age & ptratio, ptratio & lstat. 

```{r fig38, fig.path="figures/",fig.dim=c(12,12)}
km <-kmeans(boston_scaled2, centers = 2)
pairs(boston_scaled2, col = km$cluster)
```
```{r readdata 33,echo=TRUE,message=FALSE,warning=FALSE}
km <-kmeans(boston_scaled2, centers = 2)
str(km)
```

## K-meand and LDA fitting

Start again with data reloading and scaling
```{r readdata 27,echo=TRUE,message=FALSE,warning=FALSE}
library(MASS)
library(ggplot2)
library(tidyr)
library(cluster)
data("Boston")
boston_scaled3 <- scale(Boston)
boston_scaled3<-as.data.frame(boston_scaled3)
```

Number of clusters is selected to be 5 and clusters are target classess.
```{r readdata 28,echo=TRUE,message=FALSE,warning=FALSE}
km_4 <-kmeans(boston_scaled3, centers = 5)
lda.fit2 <- lda(km_4$cluster ~., data = boston_scaled3)
lda.fit2
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
  heads <- coef(x)
  arrows(x0 = 0, y0 = 0, 
         x1 = myscale * heads[,choices[1]], 
         y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
  text(myscale * heads[,choices], labels = row.names(heads), 
       cex = tex, col=color, pos=3)
}
```

Biplot drawing next:
```{r fig25, fig.path="figures/",fig.dim=c(12,12)}
plot(lda.fit2, dimen = 2, col=classes, pch=classes)
lda.arrows(lda.fit2, myscale = 1)
```

Samples are displayed as points while variables are displayed either as vectors, linear axes or nonlinear trajectories. In the case of categorical variables, category level points may be used to represent the levels of a categorical variable. 

Arrows for each variable point in the direction of increasing values of that variable.Rad increases meaning higher the value, the more meaningful it is in clustering. Indus points down indicating it decreases. Also Zn points out, but otherwise all variables are around zero meaning they are not influencial

## 3D Bonus
I copied the lines from the instructions and did the package installation
```{r readdata 32,echo=TRUE,message=FALSE,warning=FALSE}
model_predictors <- dplyr::select(train, -crime)
# check the dimensions
dim(model_predictors)
dim(lda.fit$scaling)
# matrix multiplication
matrix_product <- as.matrix(model_predictors) %*% lda.fit$scaling
matrix_product <- as.data.frame(matrix_product)
```

Then I tried plotting as instucted
```{r fig26, fig.path="figures/",fig.dim=c(12,12)}
library(plotly)
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers')
```
However, at this point I run into trouble with WebGL. In the help page the cube is rolling but I just did not succeed in R Studio.

## Data wrangling for exercise 5
```{r readdata 34,echo=TRUE,message=FALSE,warning=FALSE}
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", stringsAsFactors = F)
gii <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv", stringsAsFactors = F, na.strings = "..")
#checking the dimension
dim(hd)
dim(gii)
#checking the structure
str(hd)
str(gii)
summary(hd)
summary(gii)
```

Renaming the columns:
```{r readdata 35,echo=TRUE,message=FALSE,warning=FALSE}
names(hd)[names(hd) == "Human.Development.Index..HDI."] <- "HDI"
names(hd)[names(hd) == "Expected.Years.of.Education"] <- "EYE"
names(hd)[names(hd) == "Life.Expectancy.at.Birth"] <- "LEB"
names(hd)[names(hd) == "Mean.Years.of.Education"] <- "MYE"
names(hd)[names(hd) == "Gender.Inequality.Index..GII."] <- "GII"
names(hd)[names(hd) == "Maternal.Mortality.Ratio"] <- "MMR"
names(hd)[names(hd) == "Percent.Representation.in.Parliament"] <- "PerParliament"
names(hd)[names(hd) == "Population.with.Secondary.Education..Female."] <- "SecEducFemal"
names(hd)[names(hd) == "Gross.National.Income..GNI..per.Capita"] <- "GNIncPerCap"
names(hd)[names(hd) == "GNI.per.Capita.Rank.Minus.HDI.Rank"] <- "GNIMinusHDIRank"
names(gii)[names(gii) == "Adolescent.Birth.Rate"] <- "ADBR"
names(gii)[names(gii) == "Expected.Years.of.Education"] <- "EYE"
names(gii)[names(gii) == "Life.Expectancy.at.Birth"] <- "LEB"
names(gii)[names(gii) == "Mean.Years.of.Education"] <- "MYE"
names(gii)[names(gii) == "Gender.Inequality.Index..GII."] <- "GII"
names(gii)[names(gii) == "Maternal.Mortality.Ratio"] <- "MMR"
names(gii)[names(gii) == "Percent.Representation.in.Parliament"] <- "PerParliament"
names(gii)[names(gii) == "Population.with.Secondary.Education..Male."] <- "SecEducMale"
names(gii)[names(gii) == "Population.with.Secondary.Education..Female."] <- "SecEducFemal"
names(gii)[names(gii) == "Gross.National.Income..GNI..per.Capita"] <- "GNIncPerCap"
names(gii)[names(gii) == "Labour.Force.Participation.Rate..Female."] <- "LabForParFem"
names(gii)[names(gii) == "Labour.Force.Participation.Rate..Male."] <- "LabForParMale"
head(hd)
head(gii)
```

